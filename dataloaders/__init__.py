# ============= PROSTATE =============
from .rif import RIF
# 1. 导入新的静态加载器
from .prostate import ProstateStaticDataset 
import os
from torch.utils.data import DataLoader
import logging
import torch

def build_dataloader(args, clients): 

    # 3. 选择 Dataset 类
    if args.dataset == 'fundus':
        DatasetClass = RIF
    elif args.dataset == 'prostate':
        # 2. 在此处使用新的静态加载器
        DatasetClass = ProstateStaticDataset
        # (确保 args.data_root 现在指向您在步骤 1 中设置的 OUTPUT_STATIC_DIR)
    else:
        logging.error(f"Unknown dataset: {args.dataset}")
        raise ValueError(f"Unknown dataset: {args.dataset}")

    train_dls = []
    val_dls = []
    test_dls = []
    dataset_lens = []

    if args.dataset == 'prostate':
        for idx, client in enumerate(clients):
            # 4. 实例化 6:2:2 划分
            # (这里的 'split' 参数现在由 ProstateStaticDataset 处理)
            train_set = DatasetClass(client_idx=idx, base_path=args.data_root,
                                    split='train')
            valid_set = DatasetClass(client_idx=idx, base_path=args.data_root,
                                    split='val')
            test_set = DatasetClass(client_idx=idx, base_path=args.data_root,
                                    split='test')
    
            logging.info('{} train  dataset (60%): {}'.format(client, len(train_set)))
            logging.info('{} val    dataset (20%): {}'.format(client, len(valid_set)))
            logging.info('{} test   dataset (20%): {}'.format(client, len(test_set)))
    
            # ... (DataLoader 创建不变) ...
            train_loader = torch.utils.data.DataLoader(train_set, batch_size=args.batch_size,
                                                shuffle=True, drop_last=True)
            valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=args.batch_size,
                                                shuffle=False, drop_last=False)
            test_loader = torch.utils.data.DataLoader(test_set, batch_size=args.batch_size,
                                                shuffle=False, drop_last=False)

            train_dls.append(train_loader)
            val_dls.append(valid_loader)
            test_dls.append(test_loader)

            dataset_lens.append(len(train_set))
        
        # ... (客户端权重计算不变) ...
        client_weight = []
        total_len = sum(dataset_lens)
        if total_len > 0: 
            for i in dataset_lens:
                client_weight.append(i / total_len)
        else:
            logging.warning("Total dataset length is zero. Using uniform weights.")
            client_weight = [1.0 / len(clients)] * len(clients) if clients else []

        return train_dls, val_dls, test_dls, client_weight
    else:
        for idx, client in enumerate(clients):
            train_set = RIF(client_idx=idx, base_path=args.data_root,
                                split='train', transform=None, isVal=0)
            valid_set = RIF(client_idx=idx, base_path=args.data_root,
                                split='train', transform=None, isVal=1)
            test_set = RIF(client_idx=idx, base_path=args.data_root,
                                split='test', transform=None)
    
            logging.info('{} train  dataset: {}'.format(client, len(train_set)))
            logging.info('{} val  dataset: {}'.format(client, len(valid_set)))
            logging.info('{} test  dataset: {}'.format(client, len(test_set)))
    

            train_loader = torch.utils.data.DataLoader(train_set, batch_size=args.batch_size,
                                                shuffle=True, drop_last=True)
            valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=args.batch_size,
                                                shuffle=False, drop_last=False)
            test_loader = torch.utils.data.DataLoader(test_set, batch_size=args.batch_size,
                                                shuffle=False, drop_last=False)

            train_dls.append(train_loader)
            val_dls.append(valid_loader)
            test_dls.append(test_loader)

            dataset_lens.append(len(train_set))
        
        client_weight = []
        total_len = sum(dataset_lens)
        for i in dataset_lens:
            client_weight.append(i / total_len)

        return train_dls, val_dls, test_dls, client_weight

    

# # ============= FUNDUS =============

# from .rif import RIF
# import os
# from torch.utils.data import DataLoader
# import logging
# import torch

# def build_dataloader(args, clients):

#     train_dls = []
#     val_dls = []
#     test_dls = []

#     dataset_lens = []

    # for idx, client in enumerate(clients):
    #     train_set = RIF(client_idx=idx, base_path=args.data_root,
    #                          split='train', transform=None, isVal=0)
    #     valid_set = RIF(client_idx=idx, base_path=args.data_root,
    #                          split='train', transform=None, isVal=1)
    #     test_set = RIF(client_idx=idx, base_path=args.data_root,
    #                          split='test', transform=None)
 
    #     logging.info('{} train  dataset: {}'.format(client, len(train_set)))
    #     logging.info('{} val  dataset: {}'.format(client, len(valid_set)))
    #     logging.info('{} test  dataset: {}'.format(client, len(test_set)))
 

    #     train_loader = torch.utils.data.DataLoader(train_set, batch_size=args.batch_size,
    #                                            shuffle=True, drop_last=True)
    #     valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=args.batch_size,
    #                                            shuffle=False, drop_last=False)
    #     test_loader = torch.utils.data.DataLoader(test_set, batch_size=args.batch_size,
    #                                           shuffle=False, drop_last=False)

    #     train_dls.append(train_loader)
    #     val_dls.append(valid_loader)
    #     test_dls.append(test_loader)

    #     dataset_lens.append(len(train_set))
    
    # client_weight = []
    # total_len = sum(dataset_lens)
    # for i in dataset_lens:
    #     client_weight.append(i / total_len)

    # return train_dls, val_dls, test_dls, client_weight



